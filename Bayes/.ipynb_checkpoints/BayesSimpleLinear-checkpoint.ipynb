{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": "julia",
   "display_name": "Julia",
   "language": "julia",
   "name": "julia"
  },
  "language": "Julia",
  "name": "",
  "signature": "sha256:936e12f5b6389bd5132f747c1530a40ec02cf947eaf843124ac2c7565455e81e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bayesian Inference by Application to Simple Linear Regression\n",
      "=============================================================\n",
      "\n",
      "Simple linear regression is used to illustrate Bayesian inference, using\n",
      "the Gibbs sampler. The Gibbs sampler is used to draw samples from the\n",
      "posterior distribution of the intercept, the slope and the residual\n",
      "variance.\n",
      "\n",
      "The Model\n",
      "---------\n",
      "\n",
      "Consider the linear model:\n",
      "\n",
      "$$y_{i}=\\beta_{0}+x_{i}\\beta_{1}+e_{i}. \\tag{1}$$\n",
      "\n",
      "where for observation $i$, $y_{i}$ is the value of the dependent\n",
      "variable, $\\beta_{0}$ is the intercept, $x_{i}$ is the value of the\n",
      "independent variable and $e_{i}$ is a residual. Flat priors are used for\n",
      "the intercept and slope, and the residuals are assumed to be identically\n",
      "and independently distributed normal random variables with mean zero and\n",
      "variance $\\sigma_{e}^{2}.$ A scaled inverted chi-square prior is used\n",
      "for $\\sigma_{e}^{2}.$\n",
      "\n",
      "Simulation of Data\n",
      "------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using Distributions\n",
      "using StatsBase"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 20 #number of observations\n",
      "k = 1  #number of covariates\n",
      "\n",
      "x = reshape(sample([0,1,2],n*k),n,k)\n",
      "X = hcat(ones(Int64,n),x)\n",
      "\n",
      "betaTrue = [1,2]\n",
      "y = X*betaTrue+ randn(n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "20-element Array{Float64,1}:\n",
        "  3.79692 \n",
        "  1.07505 \n",
        "  3.76703 \n",
        "  0.247896\n",
        "  7.33989 \n",
        "  0.498773\n",
        "  1.49968 \n",
        " -0.691819\n",
        "  1.14234 \n",
        "  0.905956\n",
        "  0.300275\n",
        "  2.07429 \n",
        "  3.65302 \n",
        "  4.29803 \n",
        "  1.51421 \n",
        "  1.43622 \n",
        "  1.6611  \n",
        "  6.66723 \n",
        "  0.685156\n",
        "  3.7012  "
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Least Squares Estimation\n",
      "------------------------\n",
      "\n",
      "In matrix notation, the model (35) is\n",
      "\n",
      "$$\\mathbf{y}=\\mathbf{X}\\boldsymbol{\\beta}+\\mathbf{e},$$ where\n",
      "$$\\mathbf{X}=\\left[\\begin{array}{cc}\n",
      "1 & x_{1}\\\\\n",
      "1 & x_{2}\\\\\n",
      "\\vdots & \\vdots\\\\\n",
      "1 & x_{n}\n",
      "\\end{array}\\right].$$ Then, the least-squares estimator of\n",
      "$\\mathbf{\\beta}$ is\n",
      "$$\\mathbf{\\hat{\\boldsymbol{\\beta}}}=(\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{y},$$\n",
      "and the variance of this estimator is\n",
      "$$Var(\\hat{\\mathbf{\\boldsymbol{\\beta}}})=(\\mathbf{X}'\\mathbf{X})^{-1}\\sigma_{e}^{2}.$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Calculations in Julia:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "XPX = X'X\n",
      "rhs = X'y\n",
      "XPXi= inv(XPX)\n",
      "println(XPXi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "07777777777777778 -0.05555555555555555\n",
        " -0.05555555555555555 0.1111111111111111]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "betaHat = XPXi*rhs\n",
      "println(betaHat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8929004605401287,2.7714437423974676]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eHat = y - X*betaHat\n",
      "resVar = eHat'eHat/(n-2)\n",
      "println(resVar)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9875269795569928]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bayesian Inference\n",
      "------------------\n",
      "\n",
      "Consider making inferences about $\\boldsymbol{\\beta}$ from\n",
      "$f(\\boldsymbol{\\beta}|\\mathbf{y},\\sigma_{e}^{2}).$ By using the Bayes\n",
      "theorem, this conditional density is written as\n",
      "\n",
      "\n",
      "$$\\begin{eqnarray}\n",
      "f(\\boldsymbol{\\beta}|\\mathbf{y},\\sigma_{e}^{2}) & = & \\frac{f(\\mathbf{y}|\\boldsymbol{\\beta},\\sigma_{e}^{2})f(\\boldsymbol{\\beta})f(\\sigma_{e}^{2})}{f(\\mathbf{y},\\sigma_{e}^{2})}\\nonumber \\\\\n",
      " & \\propto & f(\\mathbf{y}|\\boldsymbol{\\beta},\\sigma_{e}^{2})f(\\boldsymbol{\\beta})f(\\sigma_{e}^{2})\\nonumber \\\\\n",
      " & \\propto & f(\\mathbf{y}|\\boldsymbol{\\beta},\\sigma_{e}^{2})\\nonumber \\\\\n",
      " & = & (2\\pi\\sigma_{e}^{2})^{-n/2}\\exp\\left\\{ -\\frac{1}{2}\\frac{(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})'(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})}{\\sigma_{e}^{2}}\\right\\}\\tag{36}\n",
      "\\end{eqnarray}$$\n",
      "\n",
      "which looks like the $n$-dimensional normal density of $\\mathbf{y}$ with\n",
      "mean $\\mathbf{X}\\boldsymbol{\\beta}$ and covariance matrix\n",
      "$\\mathbf{I}\\sigma_{e}^{2}.$ But,\n",
      "$f(\\boldsymbol{\\beta}|\\mathbf{y},\\sigma_{e}^{2})$ should be a\n",
      "two-dimensional density. So, the quadratic\n",
      "$Q=(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})'(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})$\n",
      "in the exponent of (36) is rearranged as\n",
      "\n",
      "$$\\begin{eqnarray}\n",
      "Q & = & (\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})'(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})\\\\\n",
      " & = & \\mathbf{y}'\\mathbf{y}-2\\mathbf{y}'\\mbox{X}\\boldsymbol{\\beta}+\\boldsymbol{\\beta}'(\\mathbf{X}'\\mathbf{X})\\boldsymbol{\\beta}\\\\\n",
      " & = & \\mathbf{y}'\\mathbf{y}+(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})'(\\mathbf{X}'\\mathbf{X})(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})-\\hat{\\boldsymbol{\\beta}}'(\\mathbf{X}'\\mathbf{X})\\hat{\\boldsymbol{\\beta}},\n",
      "\\end{eqnarray}$$\n",
      "\n",
      "where $\\hat{\\boldsymbol{\\beta}}$ is the solution to\n",
      "$(\\mathbf{X}'\\mathbf{X})\\hat{\\boldsymbol{\\beta}}=\\mathbf{X}'\\mathbf{y}$,\n",
      "which is the least-squares estimator of $\\boldsymbol{\\beta}$. In this\n",
      "expression, only the second term depends on $\\boldsymbol{\\beta}$. Thus,\n",
      "$f(\\boldsymbol{\\beta}|\\mathbf{y},\\sigma_{e}^{2})$ can be written as\n",
      "\n",
      "$$\n",
      "f(\\boldsymbol{\\beta}|\\mathbf{y},\\sigma_{e}^{2})\\propto\\exp\\left\\{ -\\frac{1}{2}\\frac{(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})'(\\mathbf{X}'\\mathbf{X})(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})}{\\sigma_{e}^{2}}\\right\\},\n",
      "$$\n",
      "\n",
      "which can be recognized as proportional to the density for a\n",
      "two-dimensional normal distribution with mean $\\hat{\\boldsymbol{\\beta}}$\n",
      "and variance $(\\mathbf{X}'\\mathbf{X})^{-1}\\sigma_{e}^{2}$. Thus, in this\n",
      "simple setting, the posterior mean of $\\boldsymbol{\\beta}$ is given by\n",
      "the least-squares estimate, and drawing samples from the posterior are\n",
      "not needed. But, to illustrate the Gibbs sampler, we will apply it to\n",
      "this simple example.\n",
      "\n",
      "### Gibbs Sampler for $\\boldsymbol{\\beta}$\n",
      "\n",
      "The simple regression model can be written as\n",
      "$$\\mathbf{y=}\\mathbf{1}\\beta_{0}+\\mathbf{x}\\beta_{1}+\\mathbf{e}.$$ In\n",
      "the Gibbs sampler, $\\beta_{0}$ is sampled from its full-conditional\n",
      "posterior: $f(\\beta_{0}|\\mathbf{y},\\beta_{1},\\sigma_{e}^{2}).$ This\n",
      "conditional distribution is computed for the current values of\n",
      "$\\beta_{1}$ and $\\sigma_{e}^{2}.$ So, we can write the model as\n",
      "$$\\mathbf{w}_{0}=\\mathbf{1}\\beta_{0}+\\mathbf{e},$$ where\n",
      "$\\mathbf{w}_{0}=\\mathbf{y}-\\mathbf{x}\\beta_{1}.$ Then, the least-squares\n",
      "estimator of $\\beta_{0}$ is\n",
      "$$\\hat{\\beta}_{0}=\\frac{\\mathbf{1}'\\mathbf{w}_{0}}{\\mathbf{1}'\\mathbf{1}},$$\n",
      "and the variance of this estimator is\n",
      "$$Var(\\hat{\\beta_{0}})=\\frac{\\sigma_{e}^{2}}{\\mathbf{1}'\\mathbf{1}}.$$\n",
      "By applying the strategy used to derive\n",
      "$f(\\boldsymbol{\\beta}|\\mathbf{y},\\sigma_{e}^{2})$ above, the\n",
      "full-conditional posterior for $\\beta_{0}$ can be shown to be a normal\n",
      "distribution with mean $\\hat{\\beta_{0}}$ and variance\n",
      "$\\frac{\\sigma_{e}^{2}}{\\mathbf{1}'\\mathbf{1}}.$ Similarly, the\n",
      "full-conditional posterior for $\\beta_{1}$ is a normal distribution with\n",
      "mean\n",
      "$$\\hat{\\beta}_{1}=\\frac{\\mathbf{x}'\\mathbf{w}_{1}}{\\mathbf{x}'\\mathbf{x}}$$\n",
      "and variance $\\frac{\\sigma_{e}^{2}}{\\mathbf{x}'\\mathbf{x}}$, where\n",
      "$\\mathbf{w}_{1}=\\mathbf{y}-1\\beta_{0}.$ In the calculations below, we\n",
      "will use the true value of $\\sigma_{e}^{2}.$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Calculations in Julia:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# loop for Gibbs sampler\n",
      "niter = 10000 # number of samples\n",
      "b     = [0.0, 0.0]\n",
      "meanB = [0.0, 0.0]\n",
      "\n",
      "for iter = 1:niter\n",
      "    \n",
      "    # sampling intercept\n",
      "    w = y - X[:,2] * b[2]\n",
      "    x = X[:,1]\n",
      "    xpxi = 1/(x'x)[1,1]\n",
      "    bHat = (xpxi*x'w)[1,1] \n",
      "    b[1] = rand(Normal(bHat, sqrt(xpxi))) # using residual var = 1 \n",
      "    \n",
      "    # sampling slope\n",
      "    w = y - X[:,1]*b[1]\n",
      "    x = X[:,2]\n",
      "    xpxi = 1/(x'x)[1,1]\n",
      "    bHat = (xpxi*x'w)[1,1]\n",
      "    b[2] = rand(Normal(bHat, sqrt(xpxi))) # using residual var = 1 \n",
      "    meanB = meanB + b    \n",
      "\n",
      "    if ((iter%1000) == 0)\n",
      "        @printf(\"Intercept = %6.3f \\n\", meanB[1]/iter)\n",
      "        @printf(\"Slope     = %6.3f \\n\", meanB[2]/iter)\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Intercept =  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.900 \n",
        "Slope     =  2.769 \n",
        "Intercept =  0.898 \n",
        "Slope     =  2.768 \n",
        "Intercept =  0.898 \n",
        "Slope     =  2.767 \n",
        "Intercept =  0.900 \n",
        "Slope     =  2.763 \n",
        "Intercept =  0.891 \n",
        "Slope     =  2.772 \n",
        "Intercept =  0.891 \n",
        "Slope     =  2.773 \n",
        "Intercept =  0.890 \n",
        "Slope     =  2.774 \n",
        "Intercept =  0.888 \n",
        "Slope     =  2.777 \n",
        "Intercept =  0.889 \n",
        "Slope     =  2.775 \n",
        "Intercept =  0.889 \n",
        "Slope     =  2.776 \n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Full-conditional Posterior for $\\sigma_{e}^{2}$\n",
      "\n",
      "Recall that we assumed a scaled inverted chi-square prior for\n",
      "$\\sigma_{e}^{2}$. The density function for this is:\n",
      "\n",
      "$$f(\\sigma_{e}^{2})=\\frac{(S_{e}^{2}\\nu_{e}/2)^{\\nu_{e}/2}}{\\Gamma(\\nu_{e}/2)}(\\sigma_{e}^{2})^{-(2+\\nu_{e})/2}\\exp\\left\\{ -\\frac{\\nu_{e}S_{e}^{2}}{2\\sigma_{e}^{2}}\\right\\},\\tag{37}$$\n",
      "\n",
      "where $S_{e}^{2}$ and $\\nu_{e}$ are the scale and the degrees of freedom\n",
      "parameters for this distribution. Applying Bayes theorem to combine this\n",
      "prior with the \u201clikelihood\u201d (given in (36)), the full-conditional\n",
      "posterior for the residual variance can be written as\n",
      "\n",
      "$$\\begin{aligned}\n",
      "f(\\sigma_{e}^{2}|\\mathbf{y},\\boldsymbol{\\beta}) \n",
      "& = \\frac{f(\\mathbf{y}|\\boldsymbol{\\beta},\\sigma_{e}^{2})f(\\boldsymbol{\\beta})f(\\sigma_{e}^{2})}{f(\\mathbf{y},\\boldsymbol{\\beta})}\\nonumber \\\\\n",
      "& \\propto f(\\mathbf{y}|\\boldsymbol{\\beta},\\sigma_{e}^{2})f(\\boldsymbol{\\beta})f(\\sigma_{e}^{2})\\nonumber \\\\\n",
      "& \\propto (\\sigma_{e}^{2})^{-n/2}\\exp\\left\\{ -\\frac{1}{2}\\frac{(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})'(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})}{\\sigma_{e}^{2}}\\right\\} \\nonumber \\\\\n",
      "& \\times (\\sigma_{e}^{2})^{-(2+\\nu_{e})/2}\\exp\\left\\{ -\\frac{\\nu_{e}S_{e}^{2}}{2\\sigma_{e}^{2}}\\right\\} \\nonumber \\\\\n",
      "& = (\\sigma_{e}^{2})^{-(n+2+\\nu_{e})/2}\\exp\\left\\{ -\\frac{(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})'(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})+\\nu_{e}S_{e}^{2}}{2\\sigma_{e}^{2}}\\right\\}.\n",
      "\\end{aligned}\\tag{38}$$\n",
      "\n",
      "Comparing (38) with (37), can see that it is proportional\n",
      "to a scaled inverse chi-squared density with $\\tilde{\\nu}_{e}=n+\\nu_{e}$\n",
      "degrees of freedom and\n",
      "$\\tilde{S_{e}^{2}}=\\frac{(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})'(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})+\\nu_{e}S_{e}^{2}}{\\tilde{\\nu_{e}}}$\n",
      "scale parameter. A sample from this density can be obtained as\n",
      "$\\frac{(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})'(\\mathbf{y}-\\mathbf{X}\\boldsymbol{\\beta})+\\nu_{e}S_{e}^{2}}{\\chi_{\\tilde{\\nu_{e}}}^{2}}$,\n",
      "where $\\chi_{\\tilde{\\nu_{e}}}^{2}$ is a chi-squared random variable with\n",
      "$\\tilde{\\nu_{e}}$ degrees of freedom."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise\n",
      "\n",
      "In the Julia script given here, the simulated value of the residual variance\n",
      "was used in the sampling of $\\boldsymbol{\\beta}$. Extend this script to\n",
      "also sample $\\sigma_{e}^{2}$ from its full-conditional posterior given\n",
      "above. In Julia, rand(Chisq($\\nu$),1) gives a chi-squared random variable with\n",
      "$\\nu$ degrees of freedom. Solutions can be found [here](solutions/BayesSimpleLinearExercise.ipynb) where flat priors for $\\sigma_{e}^{2}$ is used."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Model with Normal Prior for Slope\n",
      "---------------------------------\n",
      "\n",
      "Here we consider a model with a flat prior for $\\beta_{0}$ and a normal\n",
      "prior for the slope: \n",
      "\n",
      "$$\\beta_{1}\\sim N(0,\\sigma_{\\beta}^{2}),$$ \n",
      "\n",
      "where $\\sigma_{\\beta}^{2}$ is assumed to be known. Then, the full-conditional\n",
      "posterior for $\\theta'=[\\boldsymbol{\\beta},\\sigma_{e}^{2}]$ is\n",
      "\n",
      "$$\\begin{aligned}\n",
      "f(\\boldsymbol{\\theta}|\\mathbf{y}) \n",
      "& \\propto f(\\mathbf{y}|\\boldsymbol{\\theta})f(\\boldsymbol{\\theta})\\\\\n",
      "& \\propto \\left(\\sigma_{e}^{2}\\right)^{-n/2}\\exp\\left\\{ -\\frac{(\\mathbf{y}-\\mathbf{1}\\beta_{0}-\\mathbf{x}\\beta_{1})'(\\mathbf{y}-\\mathbf{1}\\beta_{0}-\\mathbf{x}\\beta_{1})}{2\\sigma_{e}^{2}}\\right\\} \\\\\n",
      "& \\times \\left(\\sigma_{\\beta}^{2}\\right)^{-1/2}\\exp\\left\\{ -\\frac{\\beta_{1}^{2}}{2\\sigma_{\\beta}^{2}}\\right\\} \\\\\n",
      "& \\times (\\sigma_{e}^{2})^{-(2+\\nu_{e})/2}\\exp\\left\\{ -\\frac{\\nu_{e}S_{e}^{2}}{2\\sigma_{e}^{2}}\\right\\} .\\\\\n",
      "\\end{aligned}$$\n",
      "\n",
      "### Full-conditional for $\\beta_{1}$:\n",
      "\n",
      "The full-conditional for $\\beta_{1}$ is obtained by dropping all terms\n",
      "and factors that do not involve $\\beta_{1}$:\n",
      "\n",
      "$$\\begin{aligned}\n",
      "f(\\beta_{1}|\\text{ELSE}) \n",
      "& \\propto \\exp\\left\\{ -\\frac{(\\mathbf{y}-\\mathbf{1}\\beta_{0}-\\mathbf{x}\\beta_{1})'(\\mathbf{y}-\\mathbf{1}\\beta_{0}-\\mathbf{x}\\beta_{1})}{2\\sigma_{e}^{2}}\\right\\} \\times \\exp\\left\\{ -\\frac{\\beta_{1}^{2}}{2\\sigma_{\\beta}^{2}}\\right\\} \\\\\n",
      "& \\propto \\exp\\left\\{ -\\frac{\\mathbf{w}'\\mathbf{w}-2\\mathbf{w}'\\mathbf{x}\\beta_{1}+\\beta_{1}^{2}(\\mathbf{x}'\\mathbf{x}+\\sigma_{e}^{2}/\\sigma_{\\beta}^{2})}{2\\sigma_{e}^{2}}\\right\\} \\\\\n",
      "& \\propto \\exp\\left\\{ -\\frac{\\mathbf{w}'\\mathbf{w}-(\\beta_{1}-\\hat{\\beta}_{1})^{2}(\\mathbf{x}'\\mathbf{x}+\\sigma_{e}^{2}/\\sigma_{\\beta}^{2})-\\hat{\\beta}_{1}^{2}(\\mathbf{x}'\\mathbf{x}+\\sigma_{e}^{2}/\\sigma_{\\beta}^{2})}{2\\sigma_{e}^{2}}\\right\\} \\\\\n",
      "& \\propto \\exp\\left\\{ -\\frac{(\\beta_{1}-\\hat{\\beta}_{1})^{2}}{\\frac{2\\sigma_{e}^{2}}{(\\mathbf{x}'\\mathbf{x}+\\sigma_{e}^{2}/\\sigma_{\\beta}^{2})}}\\right\\} ,\n",
      "\\end{aligned}$$\n",
      "\n",
      "where\n",
      "$$\\hat{\\beta}_{1}=\\frac{\\mathbf{x}'\\mathbf{w}}{(\\mathbf{x}'\\mathbf{x}+\\sigma_{e}^{2}/\\sigma_{\\beta}^{2})},$$\n",
      "and $\\mathbf{w}=\\mathbf{y}-\\mathbf{1}\\beta_{0}.$ So, the\n",
      "full-conditional posterior for $\\beta_{1}$ is a normal distribution with\n",
      "$ $mean $\\hat{\\beta}_{1}$ and variance\n",
      "$\\frac{\\sigma_{e}^{2}}{(\\mathbf{x}'\\mathbf{x}+\\sigma_{e}^{2}/\\sigma_{\\beta}^{2})}.$\n",
      "\n",
      "### Exercise\n",
      "\n",
      "1.  Use Julia to simulate a vector of 1000 values for $\\beta_{1}$ from a\n",
      "    normal distribution with mean zero and variance 3. Use the randn\n",
      "    command for this. Plot a histogram of these values. Use PyPlot.plt.hist for drawing a histogram.\n",
      "\n",
      "2.  Using a value of 1 for $\\beta_{0}$ and one of the sampled values of\n",
      "    $\\beta_{1}$, generate a vector of observations, $\\mathbf{y},$ that\n",
      "    follows a simple linear regression model. Use $\\sigma_{e}^{2}=5$ to\n",
      "    simulate $\\mathbf{y}.$\n",
      "\n",
      "3.  Use the Gibbs sampler to draw 10,000 samples for $\\beta_{1}$ from\n",
      "    its posterior distribution.\n",
      "\n",
      "    1.  Compute the mean and variance of the sampled values.\n",
      "\n",
      "    2.  Draw a histogram of the sampled values. Compare with prior."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}